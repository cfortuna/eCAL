{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Calculating energy consumption for MLP_practical with 3 layers and hidden size 10\n",
      "Calculating energy consumption for MLP_practical with 4 layers and hidden size 10\n",
      "Calculating energy consumption for MLP_practical with 5 layers and hidden size 10\n",
      "Calculating energy consumption for MLP_practical with 6 layers and hidden size 10\n",
      "Calculating energy consumption for MLP_practical with 7 layers and hidden size 10\n",
      "Calculating energy consumption for CNN_practical with 3 layers and hidden size 10\n",
      "Calculating energy consumption for CNN_practical with 4 layers and hidden size 10\n",
      "Calculating energy consumption for CNN_practical with 5 layers and hidden size 10\n",
      "Calculating energy consumption for CNN_practical with 6 layers and hidden size 10\n",
      "Calculating energy consumption for CNN_practical with 7 layers and hidden size 10\n",
      "Calculating energy consumption for KAN with 3 layers and hidden size 10\n",
      "Calculating energy consumption for KAN with 4 layers and hidden size 10\n",
      "Calculating energy consumption for KAN with 5 layers and hidden size 10\n",
      "Calculating energy consumption for KAN with 6 layers and hidden size 10\n",
      "Calculating energy consumption for KAN with 7 layers and hidden size 10\n",
      "Calculating energy consumption for Transformer with 3 layers and hidden size 10\n",
      "Calculating energy consumption for Transformer with 4 layers and hidden size 10\n",
      "Calculating energy consumption for Transformer with 5 layers and hidden size 10\n",
      "Calculating energy consumption for Transformer with 6 layers and hidden size 10\n",
      "Calculating energy consumption for Transformer with 7 layers and hidden size 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MLP_practical</th>\n",
       "      <th>CNN_practical</th>\n",
       "      <th>KAN</th>\n",
       "      <th>Transformer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>0.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>10</th>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.596992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.030013</td>\n",
       "      <td>0.022784</td>\n",
       "      <td>0.745984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.112507</td>\n",
       "      <td>0.028160</td>\n",
       "      <td>0.894976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.434780</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>1.043968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MLP_practical  CNN_practical       KAN  Transformer\n",
       "3 10       0.001178       0.002550  0.012032     0.448000\n",
       "4 10       0.001715       0.008428  0.017408     0.596992\n",
       "5 10       0.002253       0.030013  0.022784     0.745984\n",
       "6 10       0.002790       0.112507  0.028160     0.894976\n",
       "7 10       0.003328       0.434780  0.033536     1.043968"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path().resolve().parent  # go up one level from notebookâ€™s folder\n",
    "sys.path.append(str(root))\n",
    "\n",
    "import calculators.ToyModels as toy_models\n",
    "from calculators.Training import Training\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device(\"mps\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "######################################## Data Preprocessing ########################################\n",
    "PREPROCESSING_TYPE = \"normalization\" # set the preprocessing to apply to the data options: normalization, min_max_scaling, GADF\n",
    "\n",
    "REAL_INPUT_SIZE = 10 ## CHANGE SIZE HERE\n",
    "\n",
    "######################################## Training ########################################\n",
    "MODEL_NAME =\"SimpleCNN\" # set which model to use examples: KAN, resnet18, baichuan-inc/Baichuan-13B-Chat\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "# INPUT_SIZE = (1, 3, 224, 224) # 4d input for resnet # (1,128) # batch, max_seq_length for llm\n",
    "if MODEL_NAME == \"SimpleCNN\":\n",
    "    INPUT_SIZE = (1, 1, REAL_INPUT_SIZE) # 4d input for resnet # (1,128) # batch, max_seq_length for llm\n",
    "else:\n",
    "    INPUT_SIZE = (1, REAL_INPUT_SIZE) # \n",
    "\n",
    "EVALUATION_STRATEGY = \"cross_validation\" # set the evaluation strategy options: cross_validation, train_test_split\n",
    "K_FOLDS = 5 # Only used if EVALUATION_STRATEGY is cross_validation\n",
    "SPLIT_RATIO = 0.8 # Only used if EVALUATION_STRATEGY is train_test_split\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "GRID_SIZE = 5\n",
    "NUM_CLASSES = 2\n",
    "DIN = REAL_INPUT_SIZE\n",
    "DOUT = 2\n",
    "\n",
    "# Transformer specific parameters\n",
    "CONTEXT_LENGTH = REAL_INPUT_SIZE  \n",
    "EMBEDDING_SIZE = 16  \n",
    "NUM_HEADS = 2       \n",
    "NUM_DECODER_BLOCKS = 3  \n",
    "FEED_FORWARD_SIZE = 64  \n",
    "\n",
    "######################################## Inference ########################################\n",
    "NUM_INFERENCES = 10000 # number of inferences to run\n",
    "\n",
    "\n",
    "# GENERAL CONFIG\n",
    "NUM_SAMPLES = 256 # number of samples that are used to calculate the energy consumption\n",
    "FLOAT_PRECISION = 32 # number of bits used to represent a floating point number\n",
    "PROCESSOR_FLOPS_PER_SECOND = 3e12 # theoretical maximum number of floating point operations per second for the processor\n",
    "PROCESSOR_MAX_POWER = 10 # maximum power consumption of the processor in Watts\n",
    "\n",
    "# Timeseries specific\n",
    "SAMPLE_SIZE = REAL_INPUT_SIZE # size of a single sample e.g. number of timesteps in a timeseries or number of pixels in an image\n",
    "\n",
    "\n",
    "NUM_LAYERS = [3,4,5,6,7] # K\n",
    "HIDDEN_SIZE = [10] # H\n",
    "energy_consumption  ={}\n",
    "model_names = ['MLP_practical', 'CNN_practical' ,'KAN', 'Transformer']\n",
    "calculator = None\n",
    "for model_name in model_names:\n",
    "    curr_model = {}\n",
    "    for L in NUM_LAYERS:\n",
    "        for hs in HIDDEN_SIZE:\n",
    "            #INPUT_SIZE = (1, 1, 10) #is this ok for all models?\n",
    "            print(f\"Calculating energy consumption for {model_name} with {L} layers and hidden size {hs}\")\n",
    "            calculator = None\n",
    "            if model_name == \"MLP_practical\":\n",
    "                model = toy_models.SimpleMLP_practical(input_size=REAL_INPUT_SIZE, hidden_size=hs, \n",
    "                                                       output_size=DOUT, num_layers=L).to(device)\n",
    "            elif model_name == \"CNN_practical\":\n",
    "                model = toy_models.SimpleCNN_practical(output_size=DOUT, hidden_channels=1, \n",
    "                                                       num_layers=L).to(device)\n",
    "            elif model_name == \"KAN\":\n",
    "                model = toy_models.KANLikeRegressor(\n",
    "                    input_dim=REAL_INPUT_SIZE,\n",
    "                    num_hidden_layers_per_feature_fn=L,  # Varying sub-layers\n",
    "                    nodes_per_layer_in_sub_fn=hs\n",
    "                ).to(device)\n",
    "                INPUT_SIZE = (1, REAL_INPUT_SIZE)\n",
    "            elif model_name == \"Transformer\":  # Changed from \"SimpleTransformer\" to \"Transformer\"\n",
    "                model = toy_models.Transformer(\n",
    "                    num_tokens=CONTEXT_LENGTH,\n",
    "                    num_token_vals=20, #nodes per layer\n",
    "                    num_emb=hs, #* 2,\n",
    "                    num_neurons=hs,\n",
    "                    num_heads=NUM_HEADS,\n",
    "                    num_blocks=L,\n",
    "                    device=device\n",
    "            ).to(device)\n",
    "            training = Training(\n",
    "                model_name=model,\n",
    "                num_epochs=NUM_EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                processor_flops_per_second=PROCESSOR_FLOPS_PER_SECOND,\n",
    "                processor_max_power=PROCESSOR_MAX_POWER,\n",
    "                num_samples=NUM_SAMPLES,\n",
    "                input_size=INPUT_SIZE,\n",
    "                evaluation_strategy=EVALUATION_STRATEGY,\n",
    "                k_folds=K_FOLDS,\n",
    "                split_ratio=SPLIT_RATIO,\n",
    "                calculator=calculator\n",
    "            )\n",
    "            if model_name == \"MLP\":\n",
    "                model_str = \"MLP\"\n",
    "            elif model_name == \"CNN\":\n",
    "                model_str = \"CNN\"\n",
    "            elif model_name == \"Transformer\":\n",
    "                model_str = \"Transformer\"\n",
    "            else:\n",
    "                model_str = model_name\n",
    "\n",
    "            curr_model[(L,hs)] = training.calculate_energy()['training_energy']\n",
    "    energy_consumption[model_str] = curr_model\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(energy_consumption)\n",
    "df.to_csv('energy_consumption_models_small_calflops.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
